---
layout: ue
title: 分布式高性能消息系统(Kafka MQ)的原理与实践
category: 中间件技术
tags: Kafka,MQ
keywords: "Kafka,MQ"
---

<p>一、关于Kafka的一些概念和理解</p><p><br/></p><p>Kafka是一个分布式的数据流平台，它基于独特日志文件形式，提供了高性能消息系统功能。也可以用于大数据流管道。</p><p><br/></p><p>Kafka维护了按目录划分的消息订阅源，称之为 <strong>Topic</strong>。</p><p>称发布消息到Topic的工程为<strong>生产者</strong>。</p><p>称订阅Topic和处理发布的消息的订阅源的工程为<strong>消费者</strong>。</p><p>Kafka以一个或者多个服务器组成的集群的形式运行，每个服务器被称为<strong>broker</strong>。</p><p><br/></p><p>Kafka客户端和服务器端<strong>通过TCP协议连接</strong>，并提供了Java客户端，许多其他语言的客户端也有。</p><p><br/></p><p>对于每个Topic，Kafka集群维护了分区的日志文件（分区1、分区2、分区3），每个分区（partition）是顺序的、不可改变的、一直不停地往后面追加的消息队列，称之为提交日志（commit log），每个在其中的<strong>消息都有一个称之为offset的序列号</strong>，来唯一的标识在分区里的每条消息。</p><p><br/></p><p><strong>Kafka集群保存了所有发布的消息</strong>，不管他们是否被消费，<strong>保存时间期限是可以配置的</strong>。Kafka对于性能表现对于数据的数量是恒定的，所以它处理大数据量没有任何问题。</p><p><br/></p><p><strong>消息系统通常有两个模型：排队模式和广播模式</strong>，排队模式是许多消费者同时去服务器争夺数据，但是一条数据只分发给一个消费者，广播模式是消息广播给所有消费者，每个消费者都可以拿到消息。Kafka通过consumer group统一概括了这两种模式。</p><p><br/></p><p>消费者们都给自己定了一个group name(id) 的标签，<strong>每条发布到topic的消息都会发给每个订阅的consumer group里面的一个且仅一个成员</strong>。consumers可以分布在不同的进程或者服务器上。</p><p><br/></p><p><br/></p><p><span style="font-size: 20px;"><strong>message、partition和consumer的关系</strong></span></p><p><span style="line-height: 32.4px;">1、message按一定hash逻辑分发到topic的某个partition；</span><br/></p><p>2、一个consumer可以连接多个partition；</p><p><span style="line-height: 1.8;">3、所有partition都会有consumer线程去连接，这个consumer的分配是自动的，无法指定某个consumer连接哪一个partition；</span></p><p>4、consumer连接的partitions是固定的，不会中途自动变更，比如consumer1连接的是partition1和partition3，consumer2连接的是partition2，这个分配中途不会自己变化。</p><p>5、consumer如果多于partition数，则多余的那部分consumer会连不到partition而空闲。</p><p><br/></p><p><br/></p><p><strong><span style="font-size: 20px;">Kafka服务器常用脚本命令</span></strong></p><p><br/></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-weight: 700;">启动kafka：</span></p><p style="line-height: 32.4px; white-space: normal;">bin/kafka-server-start.sh config/server.properties &amp;</p><p style="line-height: 32.4px; white-space: normal;"><br/></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-weight: 700;">停止kafka：</span></p><p style="line-height: 32.4px; white-space: normal;">bin/kafka-server-stop.sh</p><p style="line-height: 32.4px; white-space: normal;"><br/></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-weight: 700;">1、Topic操作</span></p><p style="line-height: 32.4px; white-space: normal;">创建topic：<br/></p><p style="line-height: 32.4px; white-space: normal;">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic TEST2</p><p style="line-height: 32.4px; white-space: normal;">删除topic：</p><p style="line-height: 32.4px; white-space: normal;"><span style="line-height: 32.4px;">bin/</span>kafka-topics.sh --delete --zookeeper&nbsp;<span style="line-height: 32.4px;">localhost:2181</span>&nbsp;--topic topicname</p><p style="line-height: 32.4px; white-space: normal;">查看所有topic：</p><p style="line-height: 32.4px; white-space: normal;">bin/kafka-topics.sh --list --zookeeper localhost:2181</p><p style="line-height: 32.4px; white-space: normal;">查看某个topic详情：<br/></p><p style="line-height: 32.4px; white-space: normal;">bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic topic_name</p><p style="line-height: 32.4px; white-space: normal;">修改topic：</p><p style="line-height: 32.4px; white-space: normal;">bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic TEST2 --partitions 2</p><p style="line-height: 32.4px; white-space: normal;"><br/></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-weight: 700;">2、消费消息：</span><br/></p><p style="line-height: 32.4px; white-space: normal;">bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning</p><p style="line-height: 32.4px; white-space: normal;"><br/></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-weight: 700;">3、生产消息：</span></p><p style="line-height: 32.4px; white-space: normal;">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test</p><p style="line-height: 32.4px; white-space: normal;">This is a message</p><p style="line-height: 32.4px; white-space: normal;">This is another message</p><p style="line-height: 32.4px; white-space: normal;">按ctrl+c结束（^C）</p><p><br/></p><p><span style="color: rgb(255, 0, 0);"><strong><span style="font-size: 20px;">consumer_group</span></strong></span></p><p><strong>1、查看有哪些consumer groups</strong></p><p><span style="line-height: 32.4px;">./kafka-consumer-groups.sh --bootstrap-server 172.16.1.170:9092,172.16.1.171:9092,172.16.172:9092 --list --new-consumer</span></p><p><strong>2、查看指定<span style="line-height: 32.4px;">consumer&nbsp;groups的消费情况（可以看到topic的offset）</span></strong></p><p>./kafka-consumer-groups.sh --bootstrap-server 172.16.1.170:9092,172.16.1.171:9092,172.16.172:9092 --describe --group PushConsumer_qAbA7b --new-consumer</p><pre class="brush:plain;toolbar:false">GROUP,&nbsp;TOPIC,&nbsp;PARTITION,&nbsp;CURRENT&nbsp;OFFSET,&nbsp;LOG&nbsp;END&nbsp;OFFSET,&nbsp;LAG,&nbsp;OWNER
ztest-group,&nbsp;ZTEST2,&nbsp;6,&nbsp;4987,&nbsp;4987,&nbsp;0,&nbsp;consumer-7_/172.19.15.113
ztest-group,&nbsp;ZTEST2,&nbsp;0,&nbsp;4876,&nbsp;4936,&nbsp;60,&nbsp;consumer-1_/172.19.15.113
ztest-group,&nbsp;ZTEST2,&nbsp;3,&nbsp;5008,&nbsp;5062,&nbsp;54,&nbsp;consumer-4_/172.19.15.113
ztest-group,&nbsp;ZTEST2,&nbsp;4,&nbsp;4963,&nbsp;4992,&nbsp;29,&nbsp;consumer-5_/172.19.15.113
ztest-group,&nbsp;ZTEST2,&nbsp;1,&nbsp;4900,&nbsp;4949,&nbsp;49,&nbsp;consumer-2_/172.19.15.113
ztest-group,&nbsp;ZTEST2,&nbsp;2,&nbsp;5046,&nbsp;5046,&nbsp;0,&nbsp;consumer-3_/172.19.15.113
ztest-group,&nbsp;ZTEST2,&nbsp;7,&nbsp;5051,&nbsp;5051,&nbsp;0,&nbsp;consumer-8_/172.19.15.113
ztest-group,&nbsp;ZTEST2,&nbsp;5,&nbsp;5010,&nbsp;5010,&nbsp;0,&nbsp;consumer-6_/172.19.15.113</pre><p><br/></p><p><strong>参考官方文档如下：</strong></p><h4 style="font-family: 微软雅黑; font-size: 14px; line-height: 21px; white-space: normal; widows: 1; color: rgb(46, 74, 142); background-color: rgb(255, 255, 255);"><a href="http://kafka.apache.org/documentation.html#basic_ops_consumer_group" style="cursor: pointer; color: rgb(46, 74, 142); font-size: 20px; text-decoration: underline;"><span style="font-size: 20px;">Managing Consumer Groups</span></a></h4><p><span style="font-family: 微软雅黑; line-height: 21px; widows: 1; color: rgb(51, 51, 51); font-size: 18px; background-color: rgb(255, 255, 255);">With the ConsumerGroupCommand tool, we can list, delete, or describe consumer groups. For example, to list all consumer groups across all topics:</span></p><pre style="font-family: Monaco, Consolas, Courier, &quot;Lucida Console&quot;, monospace; font-size: 14px; line-height: 21px; widows: 1; background-color: rgb(255, 255, 255);">&nbsp;&gt;&nbsp;bin/kafka-consumer-groups.sh&nbsp;--zookeeper&nbsp;localhost:2181&nbsp;--list

test-consumer-group</pre><p><span style="font-family: 微软雅黑; line-height: 21px; widows: 1; color: rgb(51, 51, 51); font-size: 18px; background-color: rgb(255, 255, 255);">To view offsets as in the previous example with the ConsumerOffsetChecker, we &quot;describe&quot; the consumer group like this:</span></p><pre style="font-family: Monaco, Consolas, Courier, &quot;Lucida Console&quot;, monospace; font-size: 14px; line-height: 21px; widows: 1; background-color: rgb(255, 255, 255);">&nbsp;&gt;&nbsp;bin/kafka-consumer-groups.sh&nbsp;--zookeeper&nbsp;localhost:2181&nbsp;--describe&nbsp;--group&nbsp;test-consumer-group

GROUP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TOPIC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PARTITION&nbsp;&nbsp;CURRENT-OFFSET&nbsp;&nbsp;LOG-END-OFFSET&nbsp;&nbsp;LAG&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;OWNER
test-consumer-group&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test-foo&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test-consumer-group_postamac.local-1456198719410-29ccd54f-0</pre><p><span style="font-family: 微软雅黑; line-height: 21px; widows: 1; color: rgb(51, 51, 51); font-size: 18px; background-color: rgb(255, 255, 255);">When you&#39;re using the&nbsp;</span><a href="http://kafka.apache.org/documentation.html#newconsumerapi" style="cursor: pointer; font-family: 微软雅黑; line-height: 21px; white-space: normal; widows: 1; color: rgb(46, 74, 142); font-weight: bold; font-size: 18px; text-decoration: underline; background-color: rgb(255, 255, 255);"><span style="font-size: 18px;">new consumer API</span></a><span style="font-family: 微软雅黑; line-height: 21px; widows: 1; color: rgb(51, 51, 51); font-size: 18px; background-color: rgb(255, 255, 255);">&nbsp;where the broker handles coordination of partition handling and rebalance, you can manage the groups with the &quot;--new-consumer&quot; flags:</span></p><pre style="font-family: Monaco, Consolas, Courier, &quot;Lucida Console&quot;, monospace; font-size: 14px; line-height: 21px; widows: 1; background-color: rgb(255, 255, 255);">&nbsp;&gt;&nbsp;bin/kafka-consumer-groups.sh&nbsp;--new-consumer&nbsp;--bootstrap-server&nbsp;broker1:9092&nbsp;--list</pre><p><br/></p><h4 style="font-family: 微软雅黑; font-size: 14px; line-height: 21px; white-space: normal; widows: 1; color: rgb(46, 74, 142); background-color: rgb(255, 255, 255);"><a href="http://kafka.apache.org/documentation.html#basic_ops_consumer_lag" style="cursor: pointer; color: rgb(46, 74, 142); font-size: 20px; text-decoration: underline;"><span style="font-size: 20px;">Checking consumer position</span></a></h4><p><span style="font-size: 18px;"><span style="font-family: 微软雅黑; line-height: 21px; widows: 1; color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);">Sometimes it&#39;s useful to see the position of your consumers. We have a tool that will show the position of all consumers in a consumer group as well as how far behind the end of the log they are. To run this tool on a consumer group named&nbsp;</span><i style="font-family: 微软雅黑; font-size: 14px; line-height: 21px; white-space: normal; widows: 1; color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);">my-group</i><span style="font-family: 微软雅黑; line-height: 21px; widows: 1; color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);">&nbsp;consuming a topic named&nbsp;</span><i style="font-family: 微软雅黑; font-size: 14px; line-height: 21px; white-space: normal; widows: 1; color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);">my-topic</i><span style="font-family: 微软雅黑; line-height: 21px; widows: 1; color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);">&nbsp;would look like this:</span></span></p><pre style="font-family: Monaco, Consolas, Courier, &quot;Lucida Console&quot;, monospace; font-size: 14px; line-height: 21px; widows: 1; background-color: rgb(255, 255, 255);">&nbsp;&gt;&nbsp;bin/kafka-run-class.sh&nbsp;kafka.tools.ConsumerOffsetChecker&nbsp;--zookeeper&nbsp;localhost:2181&nbsp;--group&nbsp;test</pre><p><span style="font-family: 微软雅黑; line-height: 21px; widows: 1; color: rgb(51, 51, 51); font-size: 18px; background-color: rgb(255, 255, 255);">Note, however, after 0.9.0, the kafka.tools.ConsumerOffsetChecker tool is deprecated and you should use the kafka.admin.ConsumerGroupCommand (or the bin/kafka-consumer-groups.sh script) to manage consumer groups, including consumers created with the&nbsp;</span><a href="http://kafka.apache.org/documentation.html#newconsumerapi" style="cursor: pointer; font-family: 微软雅黑; line-height: 21px; white-space: normal; widows: 1; color: rgb(46, 74, 142); font-weight: bold; text-decoration: underline; font-size: 18px; background-color: rgb(255, 255, 255);"><span style="font-size: 18px;">new consumer API</span></a><span style="font-family: 微软雅黑; line-height: 21px; widows: 1; color: rgb(51, 51, 51); font-size: 18px; background-color: rgb(255, 255, 255);">.</span></p><p><br/></p><p><strong>查看topic的最大和最小offset</strong></p><p><span style="color: rgb(0, 176, 80);">bin/kafka-run-class.sh kafka.tools.GetOffsetShell</span></p><p><br/></p><p><br/></p><p><strong><span style="font-size: 20px;">官方文档：</span></strong></p><p>1、<span style="color: rgb(0, 176, 80);">官方网站</span>：<a href="http://kafka.apache.org/documentation">http://kafka.apache.org/documentation</a></p><p>2、<span style="color: rgb(0, 176, 80);">官方WIKI</span>：<a href="https://cwiki.apache.org/confluence/display/KAFKA/Index">https://cwiki.apache.org/confluence/display/KAFKA/Index</a> </p><p>3、issues情况（JIRA）：<a href="https://issues.apache.org/jira/browse/KAFKA">https://issues.apache.org/jira/browse/KAFKA</a> </p><p><br/></p><p><span style="font-size: 20px;"><strong>Kafka集群配置</strong></span></p><p>kafka集群配置非常简单，在不同服务器上的kafka server<span style="text-decoration: underline;">只要连接同一个zookeeper就可以组成集群</span>。</p><p>在server.properties配置&nbsp;zookeeper.connect=172.16.1.6:2181,<span style="line-height: 32.4px;">172.16.1.7:2181,<span style="line-height: 32.4px;">172.16.1.8:2181</span></span></p><p><span style="line-height: 1.8;">实例配置如下（kafka 0.9版本），供参考：</span><br/></p><pre class="brush:plain;toolbar:false">#############################&nbsp;Server&nbsp;Basics&nbsp;#############################

#&nbsp;The&nbsp;id&nbsp;of&nbsp;the&nbsp;broker.&nbsp;This&nbsp;must&nbsp;be&nbsp;set&nbsp;to&nbsp;a&nbsp;unique&nbsp;integer&nbsp;for&nbsp;each&nbsp;broker.
broker.id=0

#############################&nbsp;Socket&nbsp;Server&nbsp;Settings&nbsp;#############################

listeners=PLAINTEXT://:9092

#&nbsp;The&nbsp;port&nbsp;the&nbsp;socket&nbsp;server&nbsp;listens&nbsp;on
port=9092

#&nbsp;Hostname&nbsp;the&nbsp;broker&nbsp;will&nbsp;bind&nbsp;to.&nbsp;If&nbsp;not&nbsp;set,&nbsp;the&nbsp;server&nbsp;will&nbsp;bind&nbsp;to&nbsp;all&nbsp;interfaces
host.name=172.16.1.170

#&nbsp;Hostname&nbsp;the&nbsp;broker&nbsp;will&nbsp;advertise&nbsp;to&nbsp;producers&nbsp;and&nbsp;consumers.&nbsp;If&nbsp;not&nbsp;set,&nbsp;it&nbsp;uses&nbsp;the
#&nbsp;value&nbsp;for&nbsp;&quot;host.name&quot;&nbsp;if&nbsp;configured.&nbsp;&nbsp;Otherwise,&nbsp;it&nbsp;will&nbsp;use&nbsp;the&nbsp;value&nbsp;returned&nbsp;from
#&nbsp;java.net.InetAddress.getCanonicalHostName().
advertised.host.name=172.16.1.170

#&nbsp;The&nbsp;port&nbsp;to&nbsp;publish&nbsp;to&nbsp;ZooKeeper&nbsp;for&nbsp;clients&nbsp;to&nbsp;use.&nbsp;If&nbsp;this&nbsp;is&nbsp;not&nbsp;set,
#&nbsp;it&nbsp;will&nbsp;publish&nbsp;the&nbsp;same&nbsp;port&nbsp;that&nbsp;the&nbsp;broker&nbsp;binds&nbsp;to.
advertised.port=9092

#&nbsp;The&nbsp;number&nbsp;of&nbsp;threads&nbsp;handling&nbsp;network&nbsp;requests
num.network.threads=3

#&nbsp;The&nbsp;number&nbsp;of&nbsp;threads&nbsp;doing&nbsp;disk&nbsp;I/O
num.io.threads=8

#&nbsp;The&nbsp;send&nbsp;buffer&nbsp;(SO_SNDBUF)&nbsp;used&nbsp;by&nbsp;the&nbsp;socket&nbsp;server
socket.send.buffer.bytes=102400

#&nbsp;The&nbsp;receive&nbsp;buffer&nbsp;(SO_RCVBUF)&nbsp;used&nbsp;by&nbsp;the&nbsp;socket&nbsp;server
socket.receive.buffer.bytes=102400

#&nbsp;The&nbsp;maximum&nbsp;size&nbsp;of&nbsp;a&nbsp;request&nbsp;that&nbsp;the&nbsp;socket&nbsp;server&nbsp;will&nbsp;accept&nbsp;(protection&nbsp;against&nbsp;OOM)
socket.request.max.bytes=104857600


#############################&nbsp;Log&nbsp;Basics&nbsp;#############################

#&nbsp;A&nbsp;comma&nbsp;seperated&nbsp;list&nbsp;of&nbsp;directories&nbsp;under&nbsp;which&nbsp;to&nbsp;store&nbsp;log&nbsp;files
log.dirs=/tmp/kafka-logs

#&nbsp;The&nbsp;default&nbsp;number&nbsp;of&nbsp;log&nbsp;partitions&nbsp;per&nbsp;topic.&nbsp;More&nbsp;partitions&nbsp;allow&nbsp;greater
#&nbsp;parallelism&nbsp;for&nbsp;consumption,&nbsp;but&nbsp;this&nbsp;will&nbsp;also&nbsp;result&nbsp;in&nbsp;more&nbsp;files&nbsp;across
#&nbsp;the&nbsp;brokers.
#&nbsp;add&nbsp;by&nbsp;zollty
num.partitions=3

#&nbsp;The&nbsp;number&nbsp;of&nbsp;threads&nbsp;per&nbsp;data&nbsp;directory&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;log&nbsp;recovery&nbsp;at&nbsp;startup&nbsp;and&nbsp;flushing&nbsp;at&nbsp;shutdown.
#&nbsp;This&nbsp;value&nbsp;is&nbsp;recommended&nbsp;to&nbsp;be&nbsp;increased&nbsp;for&nbsp;installations&nbsp;with&nbsp;data&nbsp;dirs&nbsp;located&nbsp;in&nbsp;RAID&nbsp;array.
num.recovery.threads.per.data.dir=1
#&nbsp;use&nbsp;2&nbsp;factors&nbsp;add&nbsp;by&nbsp;zollty
default.replication.factor=2
#############################&nbsp;Log&nbsp;Flush&nbsp;Policy&nbsp;#############################

#&nbsp;Messages&nbsp;are&nbsp;immediately&nbsp;written&nbsp;to&nbsp;the&nbsp;filesystem&nbsp;but&nbsp;by&nbsp;default&nbsp;we&nbsp;only&nbsp;fsync()&nbsp;to&nbsp;sync
#&nbsp;the&nbsp;OS&nbsp;cache&nbsp;lazily.&nbsp;The&nbsp;following&nbsp;configurations&nbsp;control&nbsp;the&nbsp;flush&nbsp;of&nbsp;data&nbsp;to&nbsp;disk.
#&nbsp;There&nbsp;are&nbsp;a&nbsp;few&nbsp;important&nbsp;trade-offs&nbsp;here:
#&nbsp;&nbsp;&nbsp;&nbsp;1.&nbsp;Durability:&nbsp;Unflushed&nbsp;data&nbsp;may&nbsp;be&nbsp;lost&nbsp;if&nbsp;you&nbsp;are&nbsp;not&nbsp;using&nbsp;replication.
#&nbsp;&nbsp;&nbsp;&nbsp;2.&nbsp;Latency:&nbsp;Very&nbsp;large&nbsp;flush&nbsp;intervals&nbsp;may&nbsp;lead&nbsp;to&nbsp;latency&nbsp;spikes&nbsp;when&nbsp;the&nbsp;flush&nbsp;does&nbsp;occur&nbsp;as&nbsp;there&nbsp;will&nbsp;be&nbsp;a&nbsp;lot&nbsp;of&nbsp;data&nbsp;to&nbsp;flush.
#&nbsp;&nbsp;&nbsp;&nbsp;3.&nbsp;Throughput:&nbsp;The&nbsp;flush&nbsp;is&nbsp;generally&nbsp;the&nbsp;most&nbsp;expensive&nbsp;operation,&nbsp;and&nbsp;a&nbsp;small&nbsp;flush&nbsp;interval&nbsp;may&nbsp;lead&nbsp;to&nbsp;exceessive&nbsp;seeks.
#&nbsp;The&nbsp;settings&nbsp;below&nbsp;allow&nbsp;one&nbsp;to&nbsp;configure&nbsp;the&nbsp;flush&nbsp;policy&nbsp;to&nbsp;flush&nbsp;data&nbsp;after&nbsp;a&nbsp;period&nbsp;of&nbsp;time&nbsp;or
#&nbsp;every&nbsp;N&nbsp;messages&nbsp;(or&nbsp;both).&nbsp;This&nbsp;can&nbsp;be&nbsp;done&nbsp;globally&nbsp;and&nbsp;overridden&nbsp;on&nbsp;a&nbsp;per-topic&nbsp;basis.

#&nbsp;The&nbsp;number&nbsp;of&nbsp;messages&nbsp;to&nbsp;accept&nbsp;before&nbsp;forcing&nbsp;a&nbsp;flush&nbsp;of&nbsp;data&nbsp;to&nbsp;disk
#log.flush.interval.messages=10000

#&nbsp;The&nbsp;maximum&nbsp;amount&nbsp;of&nbsp;time&nbsp;a&nbsp;message&nbsp;can&nbsp;sit&nbsp;in&nbsp;a&nbsp;log&nbsp;before&nbsp;we&nbsp;force&nbsp;a&nbsp;flush
#log.flush.interval.ms=1000

#############################&nbsp;Log&nbsp;Retention&nbsp;Policy&nbsp;#############################

#&nbsp;The&nbsp;following&nbsp;configurations&nbsp;control&nbsp;the&nbsp;disposal&nbsp;of&nbsp;log&nbsp;segments.&nbsp;The&nbsp;policy&nbsp;can
#&nbsp;be&nbsp;set&nbsp;to&nbsp;delete&nbsp;segments&nbsp;after&nbsp;a&nbsp;period&nbsp;of&nbsp;time,&nbsp;or&nbsp;after&nbsp;a&nbsp;given&nbsp;size&nbsp;has&nbsp;accumulated.
#&nbsp;A&nbsp;segment&nbsp;will&nbsp;be&nbsp;deleted&nbsp;whenever&nbsp;*either*&nbsp;of&nbsp;these&nbsp;criteria&nbsp;are&nbsp;met.&nbsp;Deletion&nbsp;always&nbsp;happens
#&nbsp;from&nbsp;the&nbsp;end&nbsp;of&nbsp;the&nbsp;log.

#&nbsp;The&nbsp;minimum&nbsp;age&nbsp;of&nbsp;a&nbsp;log&nbsp;file&nbsp;to&nbsp;be&nbsp;eligible&nbsp;for&nbsp;deletion
log.retention.hours=168

#&nbsp;A&nbsp;size-based&nbsp;retention&nbsp;policy&nbsp;for&nbsp;logs.&nbsp;Segments&nbsp;are&nbsp;pruned&nbsp;from&nbsp;the&nbsp;log&nbsp;as&nbsp;long&nbsp;as&nbsp;the&nbsp;remaining
#&nbsp;segments&nbsp;don&#39;t&nbsp;drop&nbsp;below&nbsp;log.retention.bytes.
#log.retention.bytes=1073741824

#&nbsp;The&nbsp;maximum&nbsp;size&nbsp;of&nbsp;a&nbsp;log&nbsp;segment&nbsp;file.&nbsp;When&nbsp;this&nbsp;size&nbsp;is&nbsp;reached&nbsp;a&nbsp;new&nbsp;log&nbsp;segment&nbsp;will&nbsp;be&nbsp;created.
log.segment.bytes=1073741824

#&nbsp;The&nbsp;interval&nbsp;at&nbsp;which&nbsp;log&nbsp;segments&nbsp;are&nbsp;checked&nbsp;to&nbsp;see&nbsp;if&nbsp;they&nbsp;can&nbsp;be&nbsp;deleted&nbsp;according
#&nbsp;to&nbsp;the&nbsp;retention&nbsp;policies
log.retention.check.interval.ms=300000

#############################&nbsp;Zookeeper&nbsp;#############################

#&nbsp;Zookeeper&nbsp;connection&nbsp;string&nbsp;(see&nbsp;zookeeper&nbsp;docs&nbsp;for&nbsp;details).
#&nbsp;This&nbsp;is&nbsp;a&nbsp;comma&nbsp;separated&nbsp;host:port&nbsp;pairs,&nbsp;each&nbsp;corresponding&nbsp;to&nbsp;a&nbsp;zk
#&nbsp;server.&nbsp;e.g.&nbsp;&quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.
#&nbsp;You&nbsp;can&nbsp;also&nbsp;append&nbsp;an&nbsp;optional&nbsp;chroot&nbsp;string&nbsp;to&nbsp;the&nbsp;urls&nbsp;to&nbsp;specify&nbsp;the
#&nbsp;root&nbsp;directory&nbsp;for&nbsp;all&nbsp;kafka&nbsp;znodes.
zookeeper.connect=172.16.1.6:2181,172.16.1.7:2181,172.16.1.8:2181

#&nbsp;Timeout&nbsp;in&nbsp;ms&nbsp;for&nbsp;connecting&nbsp;to&nbsp;zookeeper
zookeeper.connection.timeout.ms=6000

#############################################
delete.topic.enable=true</pre><p><br/></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-weight: 700; font-size: 20px;">Kafka 服务器生产配置</span></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-size: 16px;">num.network.threads=3-8</span></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-size: 16px;">queued.max.requests=500-16</span></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-size: 16px;">fetch.purgatory.purge.interval.requests=1000-100</span></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-size: 16px;">producer.purgatory.purge.interval.requests=1000-100</span></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-size: 16px;">num.replica.fetchers=1-4</span></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-size: 16px;">default.replication.factor=1-3</span></p><p style="line-height: 32.4px; white-space: normal;"><span style="font-size: 16px;">replication.factor=1-3</span></p><p style="line-height: 32.4px; white-space: normal;"><span style="line-height: 1.8; font-size: 16px;">controlled.shutdown.enable=true</span></p><p style="line-height: 32.4px; white-space: normal;">另外：</p><p style="line-height: 32.4px; white-space: normal;">From a security perspective,&nbsp;<span style="font-weight: 700;">we recommend you use the latest released version of JDK 1.8</span>&nbsp;as older freely available versions have disclosed security vulnerabilities. LinkedIn is currently running JDK 1.8 u5 (looking to upgrade to a newer version) with the&nbsp;<span style="font-weight: 700;">G1 collector</span>. If you decide to use the G1 collector (the current default) and&nbsp;<span style="font-weight: 700;">you are still on JDK 1.7, make sure you are on u51 or newer</span>. LinkedIn tried out u21 in testing, but they had a number of problems with the GC implementation in that version. LinkedIn&#39;s tuning looks like this:</p><p style="line-height: 32.4px; white-space: normal;">-Xmx6g -Xms6g -XX:MetaspaceSize=96m -XX:+UseG1GC</p><p style="line-height: 32.4px; white-space: normal;">-XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M</p><p style="line-height: 32.4px; white-space: normal;">-XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80</p><p><br/></p>